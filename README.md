1. Setting Up the Camera and Lighting Conditions of Stage
•	Camera Setup: We are using a Sony A6000 camera with 7.5mm Fisheye Lens. The fisheye lens provides a wide field of view (horizontal 161.8° vertical 106.5° viewing angle), enabling the camera to capture the entire stage in one shot. The camera was connected to dummy batter with Continuous Power Supply to keep the camera always on.
•	Lighting: The individuals on the stage have lights in three different colors (red, blue, and green) attached to their heads. The rest of the stage is kept relatively dark (less than half the maximum brightness level) to ensure that these lights stand out in the camera's view. We have also adjusted the camera configuration (shutter speed, aperture, and ISO) to make sure all the stage seems darker while those 3 different color lights are bright enough to be visible to the camera. This processing makes the task of tracking easy.
•	Capturing stage: The camera records the stage, capturing the movements of the individuals with colored lights on their heads. This video feed is then processed in real-time. 
3. Processing and Tracking person
To develop the color light tracking system, we initially need to calibrate the system. For that purpose, we captured multiple shots with three lights placed on the stage. Then, we calibrated our color detection algorithm to detect lights closer to those color ranges.
The whole calibration process is described here:
•	Frame Extraction: The video feed is broken down into individual frames. Each frame is a still image capturing a single moment in time. Processing individual frames allows the system to track movements as they occur.
•	Color Space Conversion: Frames are converted from the RGB (Red, Green, Blue) color space to the HSV (Hue, Saturation, Value) color space. HSV is more effective for color detection as it separates color information (hue) from lighting information (saturation and value). This makes it easier to identify colors under varying lighting conditions. 
•	Specify Color Values: We specify HSV ranges for each color to accurately identify those head-mounted colored lights in the frames. For instance, green might be detected within a certain hue range, with specific saturation and value thresholds.
During the test phase, the whole process works as follows:
•	Preprocessing: We capture each frame and add a Gaussian blur to smooth out the frames, reducing noise and minor fluctuations in color that could interfere with accurate detection. We apply a brightness threshold to isolate the brightly colored lights from the rest of the frames, leaving only the area of interest (the colored lights). Then, we convert it to the HSV color space (similar to the calibration step).
•	Contour Identification: We identify the contours (continuous lines forming the boundary) of each detected color in the frame. These contours provide the position and area of the coordinates for each color. We save the position of the largest contour for each color to avoid detecting the same bright color multiple times.
•	Central Point Calculation: fter identifying the largest contour for each color, we calculate the central point of these contours. This is done using image processing techniques that find the geometric center of the contour. This center is the approximate location of the light on the individual's head, providing us with a precise point to track.
•	Continuous Position Update: Our system continuously updates the position of these central points in real-time. As each new frame is processed, we recalculate the position of the lights based on the current contours. This allows us to track the movement of the individuals across the stage accurately.
•	Predictive Algorithm: In our tracking system, when a light goes undetected due to obstruction or lighting changes, we use a predictive algorithm to estimate its position based on the last known trajectory. As soon as the light is re-detected, the system seamlessly recalibrates, ensuring continuous and accurate tracking throughout the performance.
•	Send Position data: All those (X, Y) position data of 3 colors are then sent to Max Software using a specified IP address.

![image](https://github.com/yanjundesign/Cameratracking/assets/46656554/cc6fdf33-65c2-452a-8e5e-885035a4fd83)
